{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af8430d-e454-46ea-94f9-8e3dffeff4d7",
   "metadata": {},
   "source": [
    "# AIC23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b1c0f1-3534-4ac8-a8ad-4ab73a23543d",
   "metadata": {},
   "source": [
    "Load dataset and launch app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda834fa-32bf-415f-a5e4-5f575bd695f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.brain as fob\n",
    "import numpy as np\n",
    "\n",
    "dataset = fo.Dataset.from_images_dir(\"./data/keyframes\", name=None, tags=None, recursive=True)\n",
    "session = fo.launch_app(dataset, desktop=False)\n",
    "session.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a108acd-a4d3-4058-97e1-8eb4f678c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "info = dict()\n",
    "for file in os.scandir(\"map-keyframes\"):\n",
    "    if file.name[0] == '.':\n",
    "        continue\n",
    "    videoId = file.name.split(\".\")[0]\n",
    "    data = pd.read_csv(file.path)\n",
    "    info[videoId] = data.to_dict()\n",
    "    print(info[videoId]['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e877cb1b-af1e-4871-b8fb-b877568e7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    videoId, frameId = sample[\"filepath\"].split(\"/\")[-2:]\n",
    "    videoId = videoId.split(\".\")[0]\n",
    "    frameId = int(frameId.split(\".\")[0])\n",
    "    sample[\"videoId\"] = videoId\n",
    "    sample[\"n\"] = str(info[videoId]['n'][frameId-1])\n",
    "    sample[\"frameId\"] = str(info[videoId]['frame_idx'][frameId-1])\n",
    "    sample[\"pts_time\"] = str(info[videoId]['pts_time'][frameId-1])\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7bfce4-c83e-43b3-8ec3-8e4ea3626d19",
   "metadata": {},
   "source": [
    "### Embeddings of videos are provided "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde3640-040f-431e-bd84-86b438caf2bc",
   "metadata": {},
   "source": [
    "Compute embeddings (if not provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33456091-14eb-45e8-841e-2162d6e06a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foz.load_zoo_model(\"clip-vit-base32-torch\")\n",
    "embeddings = dataset.compute_embeddings(model)\n",
    "with open(\"./embeddings/keyframes.npy\", \"wb\") as f:\n",
    "    np.save(f, embeddings);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0257963-2b05-4fcf-b829-7d28f5c80f0e",
   "metadata": {},
   "source": [
    "Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed27fee-ed40-425f-8f6b-5e0bcfb131bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"./embeddings/keyframes.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23470fa8-c3f6-40cf-99f8-ac1adaa63b98",
   "metadata": {},
   "source": [
    "Compute visualization using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7c0c5-d5c3-431d-9ca6-de4ef6e160e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = fob.compute_visualization(\n",
    "    dataset, \n",
    "    embeddings=embeddings, \n",
    "    seed=51, \n",
    "    brain_key=\"img_viz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe64839-1695-433a-9140-753c4460944e",
   "metadata": {},
   "source": [
    "Compute similarity (used to sort by similarity or query by text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add4766d-c206-4a92-9e00-1a270d9706e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_index = fob.compute_similarity(\n",
    "    dataset,\n",
    "    model=\"clip-vit-base32-torch\", \n",
    "    embeddings=embeddings,       \n",
    "    brain_key=\"img_sim\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f87b9e-6d06-40ba-b6e2-e0a0b142040f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
